from bs4 import BeautifulSoup
try:
    from Scrapers.utils import simple_get
except Exception:
    from utils import simple_get
import re
root_url = "https://www.ljhooker.co.nz"
raw_url = "https://www.ljhooker.co.nz/search/property?tt=rent&pid=&r=Otago&d=51&s%5B%5D=&ss=1&bp1=&bp2=&rp1=&rp2=&b1=&b2=&pt=&b=&c=&k=&searchType=residential&op=Find+Properties&form_build_id=form-15V1TjoaVV0yQRHmp1RyDmaAglDVAJ7Y-7Yct3eaab4&form_id=residential_property_search_form&pg=2"
current_page = 1

ndA
def parse_listing(listing):
    listing_soup = BeautifulSoup(str(listing),"html.parser")
    ##############find various things
    title = listing_soup.find("h2").text
    price = re.search('\d+',listing_soup.find("div",{"class":"featured_price_boxes"}).text)
    facilities = re.findall('\d+',listing_soup.find("div",{"class":"quick_summary"}).text)
    thumbnail= "http://"+listing_soup.find("img")['src'][2:]
    #GET listing specific soup
    link= root_url+listing_soup.find("a",{"class":"property_link"},href=True)['href']
    listing_html = simple_get(link)
    listing_specific_soup = BeautifulSoup(str(listing_html),"html.parser")
    moreinfo = listing_specific_soup.find("div",{"id":"listing_description"})
    moreinfo_soup = BeautifulSoup(str(moreinfo),"html.parser")
    address = moreinfo_soup.findAll("h3")[1].text
    items = moreinfo_soup.findAll("li")
    if "No" in items[2].text:
        pet = 0
    else:
        pet = 1
    if(price!=None):
        price = price.group()
    listing_info = {"heroText":title,
                    "description":"",
                    "price":price,
                    "address":address,
                    "pet":pet,                    
                    "bedrooms":facilities[0],
                    "bathrooms":facilities[1],
                    "parking":facilities[2],
                    "url":link,
                    "image":thumbnail,
                    "agent":"hooker"}        

    return listing_info
def hooker_scrape():
    all_listings = []
    current_page = 1
    while(True):
        page_now = raw_url + "&pg="+ str(current_page)
        raw_html = simple_get(page_now)
        soup = BeautifulSoup(raw_html,"html.parser")
        finished = soup.find("li",{"class": "prev_next_button disabled"})
        listings = soup.findAll("div",{"class":"property_snippet"})
        for listing in listings:
            all_listings.append(parse_listing(listing))
        current_page +=1
        if(finished==None):
            pass
        elif("Next"== str(finished.text)):
            break
    return all_listings


